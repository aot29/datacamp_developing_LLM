{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ed1e27-de97-4e54-aca6-91ebb5112231",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch, a Deep Learning Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea02b0b-08a4-4cec-8d21-66280ee2a317",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4f659b2-4c3e-47a2-98fe-4a705df4fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # tabular data\n",
    "import numpy as np\n",
    "\n",
    "# create a tensor from a list\n",
    "lst = [[1, 2, 3], [4, 5, 6]]\n",
    "tensor = torch.tensor(lst)\n",
    "\n",
    "# create a tensor from numpy array\n",
    "np_array = np.array(lst)\n",
    "np_tensor = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd50f4e-389c-4282-9e4a-b44b55eb3c57",
   "metadata": {},
   "source": [
    "Tensor attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84d20e7f-6f49-4fa3-a9b6-48bfb4c06091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dfc9dab-5239-4c91-a68f-feb82dfec7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec2ee6ab-1e24-4b72-8b34-fb5e51049634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74169e12-d52e-44f4-975c-ead81f9a0ded",
   "metadata": {},
   "source": [
    "Tensor operation on compatible shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "618630d5-0b80-4134-9b2d-6ef85ace391b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  4,  6],\n",
       "        [ 8, 10, 12]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor + np_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "151428e2-4494-4f3c-9127-7ea8aed816ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4,  9],\n",
       "        [16, 25, 36]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * np_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ebc574-ba5c-4221-928c-d642a9c996c3",
   "metadata": {},
   "source": [
    "## First neural network\n",
    "A 2-layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80322e7d-a11f-40c0-a671-ef7603b76e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4680, -0.6139]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# input tensor with 3 features\n",
    "input_tensor = torch.tensor([[0.3471, 0.4547, -0.2356]])\n",
    "\n",
    "# first linear layer\n",
    "linear_layer = nn.Linear(in_features=3, out_features=2)\n",
    "\n",
    "# pass input through linear layer\n",
    "output = linear_layer(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58b39f0-0134-486a-9f32-2052133e6c1a",
   "metadata": {},
   "source": [
    "Each linear layer has weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa7ff458-c38e-4b7f-9a1d-f8061f4901c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4967,  0.3452,  0.5310],\n",
       "        [ 0.1092, -0.4248, -0.0738]], requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d2e031c-d2d5-4ff6-9b1f-47d1639c8555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.2638, -0.4760], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a812f8e7-2e96-4d78-bc0e-fae110b8f10e",
   "metadata": {},
   "source": [
    "A linear layer performs a matrix multiplication of input and weights, followed by adding the bias\n",
    "\n",
    "y0 = W0 * X + b0 \n",
    "\n",
    "where X is the input tensor, W0 are the weights and b0 the bias\n",
    "\n",
    "* Weights and bias are initialized randomly\n",
    "* NNs with only linear layers are called fully-connected\n",
    "* X is 2 x 3, W0 is 2 x 3, b0 is 2, y0 is 1 x 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8dcd13-7d15-4c29-91bd-3805b02ad72a",
   "metadata": {},
   "source": [
    "## Stacking layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9847827b-acef-462e-9a5d-ca8b440cc5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 layers\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 18),\n",
    "    nn.Linear(18, 20),\n",
    "    nn.Linear(20, 5)\n",
    ")\n",
    "input = torch.tensor([[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.0]])\n",
    "output = model(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91f6642-3279-4e6b-9eec-c0b5e82774cf",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "Linear layer: multiply input by weights, add bias.\n",
    "\n",
    "Non-linear layers can model more complex relationships.\n",
    "\n",
    "### Sigmoid\n",
    "* used for classification problems\n",
    "* Transform pre-activation output (e.g. an int or a float) to a flot between 0 and 1. Common threshold for classification is 0.5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e13c4ccf-73be-4b13-83a2-909630e0b682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9975]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.tensor([[6.0]])\n",
    "sigmoid = nn.Sigmoid()\n",
    "output = sigmoid(input_tensor)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a427f65a-505e-467e-9a7f-a92a331984fa",
   "metadata": {},
   "source": [
    "Common usage as last step for binary classification (= logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519c6374-2828-422b-94da-b03d2bff2752",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(6, 4), # Linear layer\n",
    "    nn.Linear(4, 1), # Linear layer\n",
    "    nn.Sigmoid() # Sigmoid activation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eda8c8-6ef0-492f-8140-d34da60b56f6",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "* For multi-class classification\n",
    "* Output vector is same size as input\n",
    "* The output is a probability distribution (each element between 0 and 1, sum is 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ccfec69-cfe3-4ede-a51a-93c08f5571d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0159, 0.1173, 0.8668]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.tensor([[4.0, 6.0, 8.0]])\n",
    "\n",
    "probabilities = nn.Softmax(dim = -1) # -1 means apply along last dimension\n",
    "probabilities(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c1c57b-209b-4589-b130-96556a3710c3",
   "metadata": {},
   "source": [
    "## Pass forward\n",
    "Generating a predictin from a model. \n",
    "\n",
    "Output can be\n",
    "* Single probability\n",
    "* Multiclass probability\n",
    "* Numerical output (regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c9dd59-8304-44f8-baa2-3856828d5968",
   "metadata": {},
   "source": [
    "Binary classifier example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dd74442-a03a-43fb-915b-5d0ac7fdbb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8924]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a small neural network for binary classification\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(8, 1),\n",
    "  nn.Sigmoid()\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ffc9a2-aca6-4cf4-95e9-79b27f9f2599",
   "metadata": {},
   "source": [
    "Linear regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1fce35b-650c-440a-bc9f-a85d02d20b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4080]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Update network below to perform a multi-class classification with four labels\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(11, 20),\n",
    "  nn.Linear(20, 12),\n",
    "  nn.Linear(12, 6),\n",
    "  nn.Linear(6, 1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4398cee-83fa-4cd7-9569-5fbab66aefbb",
   "metadata": {},
   "source": [
    "Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c2b0940-9e66-4724-90b5-73e42283c0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1614, 0.2548, 0.2402, 0.3435]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Update network below to perform a multi-class classification with four labels\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(11, 20),\n",
    "  nn.Linear(20, 12),\n",
    "  nn.Linear(12, 6),\n",
    "  nn.Linear(6, 4), \n",
    "  nn.Softmax(dim=-1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee0f42a-9a40-45c5-9d6c-da9f98240f4a",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "Assess difference between actual value ansd predicted value\n",
    "\n",
    "Takes \n",
    "* prediction ŷ, a tensor with the same dimension as the number of classes (the softmax output)\n",
    "* actual value y a float \n",
    "* outputs a float that has to be minimized\n",
    "\n",
    "loss = F(y, ŷ) \n",
    "\n",
    "During comparison: transform y using one-hot encoding, to get a tensor of the same dimension as ŷ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f114521-099b-48e6-8942-bc2e9f5e30a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "F.one_hot(torch.tensor(0), num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81872c8a-ca22-4e78-9f5f-788d03bbaf5c",
   "metadata": {},
   "source": [
    "### Cross entropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f256d35f-679f-4687-a2b1-7fe4106eba16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8131, dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "scores = torch.tensor([[-0.122, 0.105]]) # model prediction before the softmax function\n",
    "one_hot_target = torch.Tensor([[1, 0]]) # ground truth label\n",
    "criterion = CrossEntropyLoss()\n",
    "criterion(scores.double(), one_hot_target.double()) # a single float: the loss of that sample (minimize this)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8f2ff9-5551-49b4-9f3f-9e0413afdae8",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a69a852e-64bd-467d-95fe-2b32b442c8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.0619, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "y = [2]\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor(y), scores.shape[1])\n",
    "\n",
    "# Create the cross entropy loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Calculate the cross entropy loss\n",
    "loss = criterion(scores.double(), one_hot_label.double())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3744663c-8c02-471d-a504-fcdc07c6feb2",
   "metadata": {},
   "source": [
    "## Derivatives\n",
    "\n",
    "Derivative = slope = gradient\n",
    "\n",
    "When the model is created, weights are initialized randomly.\n",
    "During the first forward pass, compute gradient of the loss function. Update the model with back-propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ef39636-48d3-4bb8-bebf-5036b05787fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "sample = torch.Tensor([[1, 2, 3,4 ,5 ,6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]])\n",
    "target = torch.Tensor([[1, 0]]) # ground truth label\n",
    "\n",
    "# create a model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(16, 8),\n",
    "    nn.Linear(8, 4),\n",
    "    nn.Linear(4, 2)\n",
    ")\n",
    "prediction = model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1aa995a-ea22-4284-a014-96f78f285d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate loss and gradients\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(prediction, target)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af5a8755-68a1-4a27-9dd5-e17962564c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-3.0243e-02, -6.0486e-02, -9.0729e-02, -1.2097e-01, -1.5121e-01,\n",
       "          -1.8146e-01, -2.1170e-01, -2.4194e-01, -2.7219e-01, -3.0243e-01,\n",
       "          -3.3267e-01, -3.6291e-01, -3.9316e-01, -4.2340e-01, -4.5364e-01,\n",
       "          -4.8389e-01],\n",
       "         [ 6.0826e-02,  1.2165e-01,  1.8248e-01,  2.4330e-01,  3.0413e-01,\n",
       "           3.6496e-01,  4.2578e-01,  4.8661e-01,  5.4744e-01,  6.0826e-01,\n",
       "           6.6909e-01,  7.2991e-01,  7.9074e-01,  8.5157e-01,  9.1239e-01,\n",
       "           9.7322e-01],\n",
       "         [-7.1586e-03, -1.4317e-02, -2.1476e-02, -2.8634e-02, -3.5793e-02,\n",
       "          -4.2952e-02, -5.0110e-02, -5.7269e-02, -6.4427e-02, -7.1586e-02,\n",
       "          -7.8744e-02, -8.5903e-02, -9.3062e-02, -1.0022e-01, -1.0738e-01,\n",
       "          -1.1454e-01],\n",
       "         [ 5.3040e-02,  1.0608e-01,  1.5912e-01,  2.1216e-01,  2.6520e-01,\n",
       "           3.1824e-01,  3.7128e-01,  4.2432e-01,  4.7736e-01,  5.3040e-01,\n",
       "           5.8344e-01,  6.3648e-01,  6.8952e-01,  7.4256e-01,  7.9560e-01,\n",
       "           8.4864e-01],\n",
       "         [ 1.5507e-04,  3.1015e-04,  4.6522e-04,  6.2029e-04,  7.7536e-04,\n",
       "           9.3044e-04,  1.0855e-03,  1.2406e-03,  1.3957e-03,  1.5507e-03,\n",
       "           1.7058e-03,  1.8609e-03,  2.0159e-03,  2.1710e-03,  2.3261e-03,\n",
       "           2.4812e-03],\n",
       "         [ 3.1267e-02,  6.2534e-02,  9.3802e-02,  1.2507e-01,  1.5634e-01,\n",
       "           1.8760e-01,  2.1887e-01,  2.5014e-01,  2.8140e-01,  3.1267e-01,\n",
       "           3.4394e-01,  3.7521e-01,  4.0647e-01,  4.3774e-01,  4.6901e-01,\n",
       "           5.0028e-01],\n",
       "         [ 2.1884e-02,  4.3768e-02,  6.5652e-02,  8.7537e-02,  1.0942e-01,\n",
       "           1.3130e-01,  1.5319e-01,  1.7507e-01,  1.9696e-01,  2.1884e-01,\n",
       "           2.4073e-01,  2.6261e-01,  2.8449e-01,  3.0638e-01,  3.2826e-01,\n",
       "           3.5015e-01],\n",
       "         [ 6.2019e-02,  1.2404e-01,  1.8606e-01,  2.4808e-01,  3.1009e-01,\n",
       "           3.7211e-01,  4.3413e-01,  4.9615e-01,  5.5817e-01,  6.2019e-01,\n",
       "           6.8221e-01,  7.4423e-01,  8.0625e-01,  8.6827e-01,  9.3028e-01,\n",
       "           9.9230e-01]]),\n",
       " tensor([-0.0302,  0.0608, -0.0072,  0.0530,  0.0002,  0.0313,  0.0219,  0.0620]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Layer gradients\n",
    "model[0].weight.grad, model[0].bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b23068-773c-462a-ab35-6172da1db2d8",
   "metadata": {},
   "source": [
    "Update model parameters by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21375695-00ac-4589-95fe-09aeb9ac04a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate (small)\n",
    "lr = 0.001\n",
    "\n",
    "# Update weights\n",
    "weight = model[0].weight\n",
    "weight_grad = weight.grad\n",
    "weight = weight - lr * weight_grad\n",
    "\n",
    "# update biases\n",
    "bias = model[0].bias\n",
    "bias_grad = bias.grad\n",
    "bias = bias - lr * bias_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac554a9c-ce7d-46e3-8c17-83e1f99ef13b",
   "metadata": {},
   "source": [
    "### Gradient descent\n",
    "\n",
    "Convex functions have 1 global minimum. N on-convex functions may have several local minima. Loss functions used in NN are non-convex. The method to find the best local minimum is called gradient descent, and is implemented in PyTorch as optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2dde559-b187-40bc-b747-6d80b987ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create optimizer stochastic gradient descent\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
    "\n",
    "# automatically update parameters\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e754886-3e4e-43a1-8248-09f6b9a35d85",
   "metadata": {},
   "source": [
    "## First training loop\n",
    "\n",
    "* Create a model\n",
    "* Choose a loss function\n",
    "* Create a dataset\n",
    "* Define optimizer\n",
    "* Run a training loop\n",
    "  * Calculate loss\n",
    "  * Calculate local gradients\n",
    "  * update model params\n",
    " \n",
    "Example:\n",
    "Data science salary dataset\n",
    "* The target is the salary, so a continuous quantity _> regression problem -> last layer is a linear layer\n",
    "* Use Mean Squared Loss as loss function, as linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48db8b6b-014c-46de-93f9-9c1d686f6245",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m      5\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m      6\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# create dataset\u001b[39;00m\n\u001b[1;32m     10\u001b[0m dataset \u001b[38;5;241m=\u001b[39m TensorDataset(\n\u001b[0;32m---> 11\u001b[0m             torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mfeatures\u001b[49m)\u001b[38;5;241m.\u001b[39mfloat(),\n\u001b[1;32m     12\u001b[0m             torch\u001b[38;5;241m.\u001b[39mtensor(target)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     13\u001b[0m         )\n\u001b[1;32m     14\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DatLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# create optimizer\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# create the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 2),\n",
    "    nn.Linear(2, 1)\n",
    ")\n",
    "\n",
    "# create dataset\n",
    "dataset = TensorDataset(\n",
    "            torch.tensor(features).float(),\n",
    "            torch.tensor(target).float()\n",
    "        )\n",
    "dataloader = DatLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# create optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d35b72-ef6f-4f35-87d4-a6e979107161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        # set gradients to 0\n",
    "        optimizer.zero_grad()\n",
    "        # get feature and target\n",
    "        feature, target = data\n",
    "        # forward pass\n",
    "        pred = model(feature)\n",
    "        # compute loss and gradients\n",
    "        loss = criterion(pred, target)\n",
    "        loss.backward()\n",
    "        # update model params\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f09f8e-a475-4469-a88a-9f4a96b79536",
   "metadata": {},
   "source": [
    "Calculating the loss using numpy and pytorch\n",
    "* using MSELoss (alternative: L2 loss, mean absolute error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1359c2-7c8c-4aa9-9a96-d92834a373c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.array(10)\n",
    "y = np.array(1)\n",
    "\n",
    "# Calculate the MSELoss using NumPy\n",
    "mse_numpy = np.square(y_hat - y).mean()\n",
    "\n",
    "# Create the MSELoss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Calculate the MSELoss using the created loss function\n",
    "mse_pytorch = criterion(torch.tensor(y_hat).float(), torch.tensor(y).float())\n",
    "print(mse_pytorch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
