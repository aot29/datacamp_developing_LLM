{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae03e7b9-1861-46db-9455-4ee90eff6cf3",
   "metadata": {},
   "source": [
    "# Text classification\n",
    "__pipelines__\n",
    "* Simple interface\n",
    "* automatic model selection\n",
    "* less control\n",
    "* less flexibility in choice of task\n",
    "\n",
    "__auto classes__\n",
    "* Flexibility, customization\n",
    "* manual setup is complex\n",
    "\n",
    "Example:\n",
    "* load pre-trained model weights and tokenizer by name\n",
    "* model_name aka \"model checkpoint\"\n",
    "\n",
    "AutoModel does not provide a head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "742380cb-e1ab-4230-b8f1-8d0230766fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atroncos/anaconda3/envs/pt_llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/atroncos/anaconda3/envs/pt_llm/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "text = \"I am an example for text classification\"\n",
    "\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6b277e-577e-4f3c-97d6-d10a575a3bd8",
   "metadata": {},
   "source": [
    "Tokenize inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4373392f-135c-4a95-ad87-eb6137be98b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96a2608-81b0-4700-aa07-75a73a670efb",
   "metadata": {},
   "source": [
    "get model's hidden states:\n",
    "* pooler_output: high-level aggregated\n",
    "* last_hidden_states: raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b84c6b04-8646-447d-99d2-b8ed4f399646",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)\n",
    "pooled_output = outputs.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30e67efb-9bae-4b12-ab8a-c4861e40370b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "747b8959-26e9-4d58-b42f-83f4bc673f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a4832-b35b-46c1-b5b7-537b746eeaea",
   "metadata": {},
   "source": [
    "Forward through custom classification head to obtain class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dec4dae8-c92c-4c66-87c7-1f3d378565a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4355, 0.5645]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "classifier_head = SimpleClassifier(pooled_output.size(-1), num_classes=2)\n",
    "logits = classifier_head(pooled_output)\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4e84df-e526-4dd0-807b-c7cc181f6675",
   "metadata": {},
   "source": [
    "Autoclass with preconfigured head\n",
    "\n",
    "AutoModelForSequenceClassification: sentiment classification in a 5 star rating scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a12ee2-8438-4e8b-a8cb-707021d790fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atroncos/anaconda3/envs/pt_llm/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de0811b3-c04b-4d20-89b5-e17cc0b524f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The quality of the product was just okay.\"\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "\n",
    "predicted_class = torch.argmax(logits, dim=1).item()\n",
    "predicted_class + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04c9d5f-695f-4bc2-b69e-96acd81ad38c",
   "metadata": {},
   "source": [
    "# Text generation\n",
    "\n",
    "* AutoModelForCausalLM accepts auto-regressive models like gpt2\n",
    "* Model head for next word prediction\n",
    "* takes prompt and generates max_length tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a5606fe-6476-4301-8501-3854dab2ff14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"This is a simple example for text generation, but it's also a good way to get a feel for how the text is generated\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "prompt = \"This is a simple example for text generation,\"\n",
    "inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "output = model.generate(inputs, max_length=26)\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb37eb-fed5-4d5f-8be9-f48e07ea7d5c",
   "metadata": {},
   "source": [
    "# Datasets for text classification\n",
    "Example: load imdb reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02b397dd-6215-48ad-8099-1831141157b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = load_dataset('imdb')\n",
    "train_data = dataset['train']\n",
    "dataloader = DataLoader(train_data, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de502dbe-d73a-4754-bc53-7a9f96caf3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "------------------------------\n",
      "[\"This film was abysmal. and not in the good way as some have claimed. First off the main character is a very unattractive gingerman. Second - WTF is going on with this van love. The plot, basically, is: boy wants sex so buys a van (which, in fairness is quite cool). Unbelievably given that he looks like a newt he scores with lots of chicks! And he fails with some. Then he scores with a really hot chick and realises he loves this dowdy bird who played hard to get. Then he drag races with the hot chicks boyfriend. And he tips his van. At which point danny devito saves the day. Although he didn't need to because in tipping the van the ginger kid crossed the line first. I gave this 2 *'s as i'm willing to assume that there's some sort of 70's Vanning subculture i'm not getting and also because there's some 70's boobage too.\", \"Chris Kattan is a great sketch actor on Saturday Night Live...but he should probably leave the movie industry alone unless he gets some sort of creative control. He plays an annoyingly peppy character who basically comes off as mildly retarded and on speed. Wanna know the only funny parts? The stuff they showed in the previews. Yes, his rendition of take on me is funny. Nothing else is. ESPECIALLY when you can tell he's trying very hard to be a physical comedian, which he shouldn't have to try at because he is one. And yet, his 'demolishing the vet's office' bit comes off as cringingly bad. This movie made me develop an eye twitch. Avoid it at all costs, and keep watching SNL.\"]\n",
      "------------------------------\n",
      "Label: tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# print some examples\n",
    "i = 0\n",
    "batch = next(iter(dataloader))\n",
    "print(f\"Example {i + 1}:\")\n",
    "print(\"------------------------------\")\n",
    "print(batch['text'])\n",
    "print(\"------------------------------\")\n",
    "print(\"Label:\", batch['label'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d111e6b-0909-4edf-a2a2-cfbda60411ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
