{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50228c9e-5a3e-4cec-9e6e-c43b86b085a7",
   "metadata": {},
   "source": [
    "## Hello World\n",
    "Popular LLM: GPT, BERT, LLaMA\n",
    "\n",
    "Pre-trained LLMs: huggingface.co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc656aef-7302-4016-85ff-db5ef3541165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atroncos/anaconda3/envs/pt_llm/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': '5 stars', 'score': 0.8516697287559509}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'  # 1-to-5 stars\n",
    "sentiment_classifier = pipeline(\"text-classification\", model=model_name)\n",
    "outputs = sentiment_classifier(\"\"\"Dear seller, \n",
    "I got very impresed with the fast delivery and careful packaging of my order. \n",
    "Great experience overall, thank you!\n",
    "\"\"\")\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6d3de2-3be7-42cc-9b2e-7a24b1625918",
   "metadata": {},
   "source": [
    "## LLM tasks\n",
    "\n",
    "Language generation\n",
    "* Text: create text from scratch with a deep understanding of language and context\n",
    "* Code: generate code automatically based on requirements\n",
    "\n",
    "Language understanding\n",
    "* text classification, sentiment analysis: supervised learning task to classify text into a predefined number of classes\n",
    "* translation\n",
    "* summarization\n",
    "* intent recognition: determine purpose behind a text, e.g. in chatbots\n",
    "* QA\n",
    "* Named entity recognition: id and classify entities, i.e. people, places..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20450636-dbfc-46b9-bcb7-1eeaa1d03d09",
   "metadata": {},
   "source": [
    "### Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bdd80a8-35a7-42bc-80fe-ada098021481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Gion neighborhood in Kyoto is famous for its many historical sights and monuments. There are also temples and churches on the other side of the city. There are also museums and churches all over Kyoto. The city is famous for being a part of the historical period, since the end of World War II. However, there are still many things about Kyoto that are not really known about. Here are some of the main attractions to visit:\n",
      "\n",
      "- Osaka Station : You get the impression that the station\n"
     ]
    }
   ],
   "source": [
    "# text generation example\n",
    "llm = pipeline(\"text-generation\")\n",
    "prompt = \"The Gion neighborhood in Kyoto is famous for\"\n",
    "outputs = llm(prompt, max_length=100)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16fcb4f-c2aa-4cc7-85b0-f6696d042c27",
   "metadata": {},
   "source": [
    "The following example generates nonsense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65025f91-5557-492f-a855-9b164d6db904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atroncos/anaconda3/envs/pt_llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/atroncos/anaconda3/envs/pt_llm/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.53s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"Conil de la Frontera in Andalucia is famous for its production of olive oil, which is a staple in the region's cuisine.\\n\\nExercise: What is the main industry in the province of Cáceres?\\nAnswer: The main industry in the province of Cáceres is agriculture, particularly the production of olives and olive oil.\\n\\nExercise: What is the significance of the province of Cáceres in the history of Spain?\\nAnswer: The province of Cáceres played a significant role in the Reconquista, the period of Christian reconquest of Spain from the Moors. It was also the site of the Battle of Las Navas de Tolosa, a decisive victory for the Christians in the Reconquista.\\n\\nExercise: What is the main attraction in the province of Cáceres?\\nAnswer: The main attraction in the province of Cáceres is the city of Cáceres, known for its rich history and cultural heritage.\\n\\nExercise: What is the main industry in the province of Cáceres?\\nAnswer: The main industry in the province of Cáceres is agriculture, particularly the production of olives and olive oil.\\n\\nExercise: What is the main attraction in the province of Cáceres?\\nAnswer: The main attraction in the province of Cáceres is the city of Cáceres, known for its rich history and cultural heritage.\\n\\nExercise: What is the main industry in the province of Cáceres?\\nAnswer: The main industry in the province of Cáceres is agriculture, particularly the production of olives and olive oil.\\n\\nExercise: What is the main attraction in the province of Cáceres?\\nAnswer: The main attraction in the province of Cáceres is the city of Cáceres, known for its rich history and cultural heritage.\\n\\nExercise: What is the main industry in the province of Cáceres?\\nAnswer: The main industry in the province of Cáceres is agriculture, particularly the production of olives and olive oil.\\n\\nExercise: What is the main attraction in the province of Cáceres?\\nAnswer: The main attraction in the province of Cáceres is the city of Cáceres, known for its rich history and\"}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "#model_name = 'openai-community/gpt2'\n",
    "# model_name = 'openai-community/gpt2-medium'\n",
    "model_name = 'microsoft/phi-2'\n",
    "prompt = \"Conil de la Frontera in Andalucia is famous for\"\n",
    "llm = pipeline(\"text-generation\", model=model_name)\n",
    "outputs = llm(prompt, max_length=500, truncation=True)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9caac3dc-12cf-4656-bf6e-40daba541314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer review:\n",
      "Walking amid Gion's Machiya wooden houses is a mesmerizing experience.\n",
      "\n",
      "Hotel reponse to the customer:\n",
      "Dear valued customer, I am glad to hear you had a good stay with us. We have enjoyed our stay and I am sure you will enjoy the hospitality at the hotel. Thanks again for the good times ahead.\n",
      "\n",
      "We are delighted to hear from you and you are looking forward to having your stay with us in Bangkok. We are truly grateful to you for your hospitality and we look forward to serving you in the coming months.\n",
      "\n",
      "Cheers!\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline for text generation using the gpt2 model\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "response = \"Dear valued customer, I am glad to hear you had a good stay with us.\"\n",
    "\n",
    "# Build the prompt for the text generation LLM\n",
    "prompt = f\"Customer review:\\n{text}\\n\\nHotel reponse to the customer:\\n{response}\"\n",
    "\n",
    "# Pass the prompt to the model pipeline\n",
    "outputs = generator(prompt, max_length=150, pad_token_id=generator.tokenizer.eos_token_id)\n",
    "\n",
    "# Print the augmented sequence generated by the model\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f376d9bd-60ef-4165-a9b0-85cec2a6e584",
   "metadata": {},
   "source": [
    "### Text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3a7d045-8d7f-438f-b0a9-730607fac891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the Eiffel Tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "#model_name = 'facebook/bart-large-cnn'\n",
    "model_name = 'cnicu/t5-small-booksum'\n",
    "llm = pipeline('summarization', model=model_name)\n",
    "long_text = \"\"\"\n",
    "\\nThe tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure \n",
    "in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower \n",
    "surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years \n",
    "until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of \n",
    "300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the \n",
    "Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing \n",
    "structure in France after the Millau Viaduct.\\n\n",
    "\"\"\"\n",
    "llm(long_text, max_length=50, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd77bf4-b4ce-4ac8-921f-a1afe9fa3c15",
   "metadata": {},
   "source": [
    "### QA\n",
    "Takes 2 inputs: Question and Context, to predict an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f88cfe2-b52b-4149-bef4-54993f7a6d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.8993020057678223, 'start': 28, 'end': 34, 'answer': 'wooden'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "llm = pipeline(\"question-answering\")\n",
    "context = \"Walking amid Gion's Machiya wooden houses is a mesmerizing experience.\"\n",
    "question = \"What are Machiya houses made of?\"\n",
    "llm(question=question, context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af1c27c-420f-45d4-ab4c-1ce1c7bc817f",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17153273-48ec-4b60-8a50-71af38623ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atroncos/anaconda3/envs/pt_llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/atroncos/anaconda3/envs/pt_llm/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/atroncos/anaconda3/envs/pt_llm/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Caminar entre las casas de madera Machiya de Gion es una experiencia fascinante.'}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "llm = pipeline(\"translation_en_to_es\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
    "text = \"Walking amid Gion's Machiya wooden houses is a mesmerizing experience.\"\n",
    "llm(text, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89553014-f36d-4a00-bff1-078e14caa1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atroncos/anaconda3/envs/pt_llm/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This course on LLMs is getting very interesting.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Este curso sobre LLMs se está poniendo muy interesante\"\n",
    "\n",
    "# Define pipeline for Spanish-to-English translation\n",
    "translator = pipeline(\"translation_es_to_en\", model=\"Helsinki-NLP/opus-mt-es-en\")\n",
    "\n",
    "# Translate the input text\n",
    "translations = translator(input_text)\n",
    "\n",
    "# Access the output to print the translated text in English\n",
    "print(translations[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ef2dda-b5fd-44d3-983c-4f1ee6414238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
