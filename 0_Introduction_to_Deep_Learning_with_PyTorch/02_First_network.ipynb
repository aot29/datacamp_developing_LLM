{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ed1e27-de97-4e54-aca6-91ebb5112231",
   "metadata": {},
   "source": [
    "# Training Our First Neural Network with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c1c57b-209b-4589-b130-96556a3710c3",
   "metadata": {},
   "source": [
    "## Pass forward\n",
    "Generating a prediction from a model. \n",
    "\n",
    "Output can be\n",
    "* Single probability\n",
    "* Multiclass probability\n",
    "* Numerical output (regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c9dd59-8304-44f8-baa2-3856828d5968",
   "metadata": {},
   "source": [
    "Binary classifier example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dd74442-a03a-43fb-915b-5d0ac7fdbb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8924]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a small neural network for binary classification\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(8, 1),\n",
    "  nn.Sigmoid()\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ffc9a2-aca6-4cf4-95e9-79b27f9f2599",
   "metadata": {},
   "source": [
    "Linear regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1fce35b-650c-440a-bc9f-a85d02d20b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4080]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Update network below to perform a multi-class classification with four labels\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(11, 20),\n",
    "  nn.Linear(20, 12),\n",
    "  nn.Linear(12, 6),\n",
    "  nn.Linear(6, 1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4398cee-83fa-4cd7-9569-5fbab66aefbb",
   "metadata": {},
   "source": [
    "Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c2b0940-9e66-4724-90b5-73e42283c0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1614, 0.2548, 0.2402, 0.3435]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Update network below to perform a multi-class classification with four labels\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(11, 20),\n",
    "  nn.Linear(20, 12),\n",
    "  nn.Linear(12, 6),\n",
    "  nn.Linear(6, 4), \n",
    "  nn.Softmax(dim=-1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee0f42a-9a40-45c5-9d6c-da9f98240f4a",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "Assess difference between actual value ansd predicted value\n",
    "\n",
    "Takes \n",
    "* prediction ŷ, a tensor with the same dimension as the number of classes (the softmax output)\n",
    "* actual value y a float \n",
    "* outputs a float that has to be minimized\n",
    "\n",
    "loss = F(y, ŷ) \n",
    "\n",
    "During comparison: transform y using one-hot encoding, to get a tensor of the same dimension as ŷ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f114521-099b-48e6-8942-bc2e9f5e30a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "F.one_hot(torch.tensor(0), num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81872c8a-ca22-4e78-9f5f-788d03bbaf5c",
   "metadata": {},
   "source": [
    "### Cross entropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f256d35f-679f-4687-a2b1-7fe4106eba16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8131, dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "scores = torch.tensor([[-0.122, 0.105]]) # model prediction before the softmax function\n",
    "one_hot_target = torch.Tensor([[1, 0]]) # ground truth label\n",
    "criterion = CrossEntropyLoss()\n",
    "criterion(scores.double(), one_hot_target.double()) # a single float: the loss of that sample (minimize this)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8f2ff9-5551-49b4-9f3f-9e0413afdae8",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a69a852e-64bd-467d-95fe-2b32b442c8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.0619, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "y = [2]\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor(y), scores.shape[1])\n",
    "\n",
    "# Create the cross entropy loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Calculate the cross entropy loss\n",
    "loss = criterion(scores.double(), one_hot_label.double())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3744663c-8c02-471d-a504-fcdc07c6feb2",
   "metadata": {},
   "source": [
    "## Derivatives\n",
    "\n",
    "Derivative = slope = gradient\n",
    "\n",
    "When the model is created, weights are initialized randomly.\n",
    "During the first forward pass, compute gradient of the loss function. Update the model with back-propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ef39636-48d3-4bb8-bebf-5036b05787fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "sample = torch.Tensor([[1, 2, 3,4 ,5 ,6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]])\n",
    "target = torch.Tensor([[1, 0]]) # ground truth label\n",
    "\n",
    "# create a model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(16, 8),\n",
    "    nn.Linear(8, 4),\n",
    "    nn.Linear(4, 2)\n",
    ")\n",
    "prediction = model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1aa995a-ea22-4284-a014-96f78f285d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate loss and gradients\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(prediction, target)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af5a8755-68a1-4a27-9dd5-e17962564c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-3.0243e-02, -6.0486e-02, -9.0729e-02, -1.2097e-01, -1.5121e-01,\n",
       "          -1.8146e-01, -2.1170e-01, -2.4194e-01, -2.7219e-01, -3.0243e-01,\n",
       "          -3.3267e-01, -3.6291e-01, -3.9316e-01, -4.2340e-01, -4.5364e-01,\n",
       "          -4.8389e-01],\n",
       "         [ 6.0826e-02,  1.2165e-01,  1.8248e-01,  2.4330e-01,  3.0413e-01,\n",
       "           3.6496e-01,  4.2578e-01,  4.8661e-01,  5.4744e-01,  6.0826e-01,\n",
       "           6.6909e-01,  7.2991e-01,  7.9074e-01,  8.5157e-01,  9.1239e-01,\n",
       "           9.7322e-01],\n",
       "         [-7.1586e-03, -1.4317e-02, -2.1476e-02, -2.8634e-02, -3.5793e-02,\n",
       "          -4.2952e-02, -5.0110e-02, -5.7269e-02, -6.4427e-02, -7.1586e-02,\n",
       "          -7.8744e-02, -8.5903e-02, -9.3062e-02, -1.0022e-01, -1.0738e-01,\n",
       "          -1.1454e-01],\n",
       "         [ 5.3040e-02,  1.0608e-01,  1.5912e-01,  2.1216e-01,  2.6520e-01,\n",
       "           3.1824e-01,  3.7128e-01,  4.2432e-01,  4.7736e-01,  5.3040e-01,\n",
       "           5.8344e-01,  6.3648e-01,  6.8952e-01,  7.4256e-01,  7.9560e-01,\n",
       "           8.4864e-01],\n",
       "         [ 1.5507e-04,  3.1015e-04,  4.6522e-04,  6.2029e-04,  7.7536e-04,\n",
       "           9.3044e-04,  1.0855e-03,  1.2406e-03,  1.3957e-03,  1.5507e-03,\n",
       "           1.7058e-03,  1.8609e-03,  2.0159e-03,  2.1710e-03,  2.3261e-03,\n",
       "           2.4812e-03],\n",
       "         [ 3.1267e-02,  6.2534e-02,  9.3802e-02,  1.2507e-01,  1.5634e-01,\n",
       "           1.8760e-01,  2.1887e-01,  2.5014e-01,  2.8140e-01,  3.1267e-01,\n",
       "           3.4394e-01,  3.7521e-01,  4.0647e-01,  4.3774e-01,  4.6901e-01,\n",
       "           5.0028e-01],\n",
       "         [ 2.1884e-02,  4.3768e-02,  6.5652e-02,  8.7537e-02,  1.0942e-01,\n",
       "           1.3130e-01,  1.5319e-01,  1.7507e-01,  1.9696e-01,  2.1884e-01,\n",
       "           2.4073e-01,  2.6261e-01,  2.8449e-01,  3.0638e-01,  3.2826e-01,\n",
       "           3.5015e-01],\n",
       "         [ 6.2019e-02,  1.2404e-01,  1.8606e-01,  2.4808e-01,  3.1009e-01,\n",
       "           3.7211e-01,  4.3413e-01,  4.9615e-01,  5.5817e-01,  6.2019e-01,\n",
       "           6.8221e-01,  7.4423e-01,  8.0625e-01,  8.6827e-01,  9.3028e-01,\n",
       "           9.9230e-01]]),\n",
       " tensor([-0.0302,  0.0608, -0.0072,  0.0530,  0.0002,  0.0313,  0.0219,  0.0620]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Layer gradients\n",
    "model[0].weight.grad, model[0].bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b23068-773c-462a-ab35-6172da1db2d8",
   "metadata": {},
   "source": [
    "Update model parameters by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21375695-00ac-4589-95fe-09aeb9ac04a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate (small)\n",
    "lr = 0.001\n",
    "\n",
    "# Update weights\n",
    "weight = model[0].weight\n",
    "weight_grad = weight.grad\n",
    "weight = weight - lr * weight_grad\n",
    "\n",
    "# update biases\n",
    "bias = model[0].bias\n",
    "bias_grad = bias.grad\n",
    "bias = bias - lr * bias_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac554a9c-ce7d-46e3-8c17-83e1f99ef13b",
   "metadata": {},
   "source": [
    "### Gradient descent\n",
    "\n",
    "Convex functions have 1 global minimum. N on-convex functions may have several local minima. Loss functions used in NN are non-convex. The method to find the best local minimum is called gradient descent, and is implemented in PyTorch as optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2dde559-b187-40bc-b747-6d80b987ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create optimizer stochastic gradient descent\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
    "\n",
    "# automatically update parameters\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e754886-3e4e-43a1-8248-09f6b9a35d85",
   "metadata": {},
   "source": [
    "## First training loop\n",
    "\n",
    "* Create a model\n",
    "* Choose a loss function\n",
    "* Create a dataset\n",
    "* Define optimizer\n",
    "* Run a training loop\n",
    "  * Calculate loss\n",
    "  * Calculate local gradients\n",
    "  * update model params\n",
    " \n",
    "Example:\n",
    "Data science salary dataset\n",
    "* The target is the salary, so a continuous quantity _> regression problem -> last layer is a linear layer\n",
    "* Use Mean Squared Loss as loss function, as linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48db8b6b-014c-46de-93f9-9c1d686f6245",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m      5\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m      6\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# create dataset\u001b[39;00m\n\u001b[1;32m     10\u001b[0m dataset \u001b[38;5;241m=\u001b[39m TensorDataset(\n\u001b[0;32m---> 11\u001b[0m             torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mfeatures\u001b[49m)\u001b[38;5;241m.\u001b[39mfloat(),\n\u001b[1;32m     12\u001b[0m             torch\u001b[38;5;241m.\u001b[39mtensor(target)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     13\u001b[0m         )\n\u001b[1;32m     14\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DatLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# create optimizer\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# create the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 2),\n",
    "    nn.Linear(2, 1)\n",
    ")\n",
    "\n",
    "# create dataset\n",
    "dataset = TensorDataset(\n",
    "            torch.tensor(features).float(),\n",
    "            torch.tensor(target).float()\n",
    "        )\n",
    "dataloader = DatLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# create optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d35b72-ef6f-4f35-87d4-a6e979107161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        # set gradients to 0\n",
    "        optimizer.zero_grad()\n",
    "        # get feature and target\n",
    "        feature, target = data\n",
    "        # forward pass\n",
    "        pred = model(feature)\n",
    "        # compute loss and gradients\n",
    "        loss = criterion(pred, target)\n",
    "        loss.backward()\n",
    "        # update model params\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f09f8e-a475-4469-a88a-9f4a96b79536",
   "metadata": {},
   "source": [
    "Calculating the loss using numpy and pytorch\n",
    "* using MSELoss (alternative: L2 loss, mean absolute error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1359c2-7c8c-4aa9-9a96-d92834a373c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.array(10)\n",
    "y = np.array(1)\n",
    "\n",
    "# Calculate the MSELoss using NumPy\n",
    "mse_numpy = np.square(y_hat - y).mean()\n",
    "\n",
    "# Create the MSELoss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Calculate the MSELoss using the created loss function\n",
    "mse_pytorch = criterion(torch.tensor(y_hat).float(), torch.tensor(y).float())\n",
    "print(mse_pytorch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
