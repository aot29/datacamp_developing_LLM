{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a997dde1-9a79-45eb-a826-ad1d02b101a6",
   "metadata": {},
   "source": [
    "# Water potability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e27176a5-5d80-41db-8257-272f0f6b0699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143efe42-6010-406a-9c3e-db1cc6e33bd8",
   "metadata": {},
   "source": [
    "## Load data, split train/validate/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167c98a5-20fa-4eb3-9ead-6ecbc9cfdc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.587349</td>\n",
       "      <td>0.577747</td>\n",
       "      <td>0.386298</td>\n",
       "      <td>0.568199</td>\n",
       "      <td>0.647347</td>\n",
       "      <td>0.292985</td>\n",
       "      <td>0.654522</td>\n",
       "      <td>0.795029</td>\n",
       "      <td>0.630115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643654</td>\n",
       "      <td>0.441300</td>\n",
       "      <td>0.314381</td>\n",
       "      <td>0.439304</td>\n",
       "      <td>0.514545</td>\n",
       "      <td>0.356685</td>\n",
       "      <td>0.377248</td>\n",
       "      <td>0.202914</td>\n",
       "      <td>0.520358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.388934</td>\n",
       "      <td>0.470876</td>\n",
       "      <td>0.506122</td>\n",
       "      <td>0.524364</td>\n",
       "      <td>0.561537</td>\n",
       "      <td>0.142913</td>\n",
       "      <td>0.249922</td>\n",
       "      <td>0.401487</td>\n",
       "      <td>0.219973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.725820</td>\n",
       "      <td>0.715942</td>\n",
       "      <td>0.506141</td>\n",
       "      <td>0.521683</td>\n",
       "      <td>0.751819</td>\n",
       "      <td>0.148683</td>\n",
       "      <td>0.467200</td>\n",
       "      <td>0.658678</td>\n",
       "      <td>0.242428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.610517</td>\n",
       "      <td>0.532588</td>\n",
       "      <td>0.237701</td>\n",
       "      <td>0.270288</td>\n",
       "      <td>0.495155</td>\n",
       "      <td>0.494792</td>\n",
       "      <td>0.409721</td>\n",
       "      <td>0.469762</td>\n",
       "      <td>0.585049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph  Hardness    Solids  Chloramines   Sulfate  Conductivity  \\\n",
       "0  0.587349  0.577747  0.386298     0.568199  0.647347      0.292985   \n",
       "1  0.643654  0.441300  0.314381     0.439304  0.514545      0.356685   \n",
       "2  0.388934  0.470876  0.506122     0.524364  0.561537      0.142913   \n",
       "3  0.725820  0.715942  0.506141     0.521683  0.751819      0.148683   \n",
       "4  0.610517  0.532588  0.237701     0.270288  0.495155      0.494792   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0        0.654522         0.795029   0.630115           0  \n",
       "1        0.377248         0.202914   0.520358           0  \n",
       "2        0.249922         0.401487   0.219973           0  \n",
       "3        0.467200         0.658678   0.242428           0  \n",
       "4        0.409721         0.469762   0.585049           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "potability = pd.read_csv('water_potability.csv')\n",
    "potability.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8a1526d-459d-4c8f-8a6e-d6de37468317",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_len = potability.shape[0]\n",
    "train_len = math.floor(data_len * 0.7)\n",
    "val_len = math.floor(data_len * 0.2)\n",
    "test_len = math.floor(data_len * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f8cb05e-d5f9-410d-aaff-321065d1453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = potability.iloc[0:train_len, :]\n",
    "val_data = potability.iloc[train_len:train_len+val_len, :]\n",
    "test_data = potability.iloc[train_len + val_len:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413f4db4-1175-4d8b-a11a-a50205452e49",
   "metadata": {},
   "source": [
    "## Setup tensor datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7cf19fd-3086-46e3-a241-7ca418c9e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupTensorDataset(data):\n",
    "    # Load the different columns into two PyTorch tensors\n",
    "    X = torch.tensor(potability.iloc[:, -1].to_numpy())\n",
    "    y = torch.tensor(potability.iloc[:, 0:-1].to_numpy())\n",
    "    dataset = TensorDataset(torch.tensor(X), torch.tensor(y).float())\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c5248b1-2590-44ee-a32d-ee9381c65dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1705/1100859196.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset = TensorDataset(torch.tensor(X), torch.tensor(y).float())\n"
     ]
    }
   ],
   "source": [
    "train_dataset = setupTensorDataset(train_data)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=2)\n",
    "\n",
    "val_dataset = setupTensorDataset(val_data)\n",
    "val_loader = DataLoader(val_dataset, shuffle=True, batch_size=2)\n",
    "\n",
    "test_dataset = setupTensorDataset(test_data)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc26a3aa-5dea-4a82-8c31-db06fa948b5e",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c909add4-3f5f-4e53-bd8c-7f0bed53b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(9, 5),\n",
    "    nn.Linear(5, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "49ff2229-f164-4805-895c-de836a4a7140",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(feature)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# compute loss and gradients\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# update model params\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pt_llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pt_llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pt_llm/lib/python3.12/site-packages/torch/nn/modules/loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pt_llm/lib/python3.12/site-packages/torch/nn/functional.py:3118\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3116\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m-> 3118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3121\u001b[0m     )\n\u001b[1;32m   3123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3124\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.95) # stochastic gradient descent with default params\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    training_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # set gradients to 0\n",
    "        optimizer.zero_grad()\n",
    "        # get feature and target\n",
    "        target, feature = data\n",
    "        # forward pass\n",
    "        pred = model(feature)\n",
    "        # compute loss and gradients\n",
    "        loss = criterion(pred.float(), target.float())\n",
    "        loss.backward()\n",
    "        # update model params\n",
    "        optimizer.step()\n",
    "        # calculate and sum losses\n",
    "        training_loss += loss.item()\n",
    "    epoch_loss = training_loss / len(train_loader) # len = number of batches in dataset\n",
    "    print(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4e2f87c2-ae2b-4a18-8f05-0b0bb2c5d556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.reshape(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e2de6a1b-7154-4268-9668-5ecbdeb46ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9dc1bd8-19ec-4c37-a63b-c0b56b127350",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "loss = nn.BCELoss()\n",
    "input = torch.randn(3, 2, requires_grad=True)\n",
    "target = torch.rand(3, 2, requires_grad=False)\n",
    "output = loss(m(input), target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7529dae7-73e2-450b-a6f7-aac4c8e7b969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9969, 0.6069],\n",
       "        [0.9487, 0.5640],\n",
       "        [0.3844, 0.3170]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3932181e-bbff-47d1-a55c-80987f4652f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5518, 0.6075],\n",
       "        [0.5211, 0.2968],\n",
       "        [0.1378, 0.1513]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20b2661d-efd9-455d-9a1d-4b6917afa2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2079,  0.4369],\n",
       "        [ 0.0845, -0.8627],\n",
       "        [-1.8334, -1.7247]], requires_grad=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ed953e-900f-4708-9bca-14a419468cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
